**Generative AI Technology: Building Systems and Agents (No-Code)**

---

### **Day 1: Introduction to Generative AI**
- Course overview, objectives, and learning path
- ChatGPT usage and practical applications
- What is a Large Language Model (LLM)
- Understanding AI platforms and ecosystems
- Gen-AI as a transformative technology
- Core concepts of LLMs and their capabilities
- **Lab:** Hands-on ChatGPT exploration and prompt experimentation

### **Day 2: Understanding LLM Models and Economics**
- ChatGPT model variations: GPT-4o, GPT-4.1, GPT-4o mini
- Token-based pricing: input vs output costs
- Understanding tools in LLMs and their functions
- Web search tool integration and capabilities
- Memory tools and conversation persistence
- **Lab:** Cost calculation exercises and model comparison

### **Day 3: LLM Capabilities and Limitations**
- ChatGPT Code Interpreter tools and data analysis
- Understanding the core weaknesses of LLMs
- LLMs as probability machines: how they actually work
- Hallucinations: identification and mitigation strategies
- Knowledge limitations and training data cutoffs
- Context size constraints and memory limitations
- **Lab:** Identifying hallucinations and testing model limits

### **Day 4: Mastering Prompt Engineering**
- Advanced prompting techniques and best practices
- Context management and conversation flow
- System instructions vs user prompts
- One-shot vs few-shot prompting strategies
- Chain of thought technique for complex reasoning
- Working with text files and document processing
- Understanding LLM costs and optimization strategies
- Practical tips for effective ChatGPT usage
- **Lab:** Prompt engineering workshop with real-world scenarios

---

## **Week 2: Exploring AI Platform Alternatives**

### **Day 1: Google AI Studio and Reasoning Models**
- Google AI platform overview and capabilities
- Introduction to reasoning models and their applications
- Google AI Studio interface and features
- Gemini model family and their strengths
- Hands-on exploration of Google AI Studio
- **Lab:** Create and test prompts using Google AI Studio

### **Day 2: Comprehensive LLM Platform Tour**
- Anthropic and the Claude LLM family
- Claude's unique capabilities and conversation style
- X.ai's Grok platform and real-time capabilities
- Understanding LLM proxy services and their benefits
- OpenRouter platform for multi-model access
- **Lab:** Comparative analysis using different platforms

### **Day 3: Open Source LLM Ecosystem**
- Commercial vs Open Source models: pros and cons
- Why are LLMs expensive and what drives costs
- Technical requirements for running models locally
- Hugging Face ecosystem and community models
- Understanding model licensing and usage rights
- **Lab:** Explore Hugging Face model repository

### **Day 4: Local AI with Ollama**
- Downloading and installing Ollama from https://ollama.com/
- Running open source models on your personal computer
- Understanding hardware requirements and limitations
- Business applications and use cases for open-source models
- Privacy benefits of local AI deployment
- **Lab:** Set up and run local models using Ollama

---

## **Week 3: Vibe Coding - AI-Powered Development**

### **Day 1: Introduction to Vibe Coding**
- What is Vibe Coding: Andrej Karpathy's 2025 paradigm
- Natural language to code generation
- Vibe coding with GitHub Copilot and Visual Studio Code
- Creating basic applications through natural language
- Debugging and error fixing with AI assistance
- Updating existing applications using vibe coding
- **Lab:** Build simple applications using natural language prompts

### **Day 2: Google NotebookLM for Research**
- What is NotebookLM and why it matters
- Access via https://notebooklm.google.com/
- Connecting sources: Google Docs, PDFs, Drive files, and URLs
- Source-grounded answers with citations to your sources
- Notebook Guide: autogenerated outlines and study guides
- Audio Overview: podcast-style explanations from your sources (where available)
- Practical use cases: research synthesis, briefs, study notes, meeting prep
- Privacy and limitations: data handling, region availability, and scope
- **Lab:** Build a NotebookLM project from 2â€“3 sources; generate a Notebook Guide, test Q&A with citations, try Audio Overview, and export results to Google Docs

### **Day 3: Understanding Tools and APIs**
- Recap: What constitutes a tool in Generative AI
- LLMs and system-to-system communications
- Introduction to REST APIs and their role
- How AI agents interact with external systems
- **Lab:** Explore API concepts through practical examples

### **Day 4: Practical Application Building**
- Project: Create a weather forecast website using vibe coding
- System analysis and architecture planning
- Understanding front-end vs back-end concepts
- Coordinating between different system components
- **Lab:** Complete weather application using AI assistance

---

## **Week 4: Model Context Protocol (MCP)**

### **Day 1: AI as a Service Revolution**
- API concepts recap and modern applications
- Technology as a Service (TaaS) business models
- Creating applications with Lovable.AI platform
- Builder.AI: lessons from industry scandals
- The future of no-code/low-code AI development
- **Lab:** Explore Lovable.AI for application creation

### **Day 2: The Rise of Model Context Protocol**
- What is MCP: Anthropic's 2024 breakthrough
- Why MCP is needed: solving the integration problem
- How MCP provides tools to AI systems
- Technology becoming 'LLM friendly'
- Anthropic's influence on the AI ecosystem
- **Lab:** Understanding MCP through practical examples

### **Day 3: The Power of MCP Tools**
- Exploring tool marketplace at https://smithery.ai/
- Empowering development environments with Gmail MCP
- Context7 MCP for up-to-date documentation
- Security concerns and pitfalls of MCP implementations
- **Lab:** Set up and configure basic MCP tools

### **Day 4: MCP in Practice**
- Hands-on MCP implementation workshop
- Empowering Cursor/VSCode with Context7
- Overcoming outdated LLM information limitations
- Introduction to Streamlit for rapid app development
- Building sample chatbots with Streamlit and Context7
- **Lab:** Create a functional chatbot using Vibe MCP tools

---

## **Week 5: Retrieval Augmented Generation (RAG)**

### **Day 1: RAG Fundamentals**
- What is Retrieval Augmented Generation
- Why RAG is the most widely used LLM technique in industry
- Context management and information retrieval
- Core challenges in RAG implementation
- Making LLMs domain experts through RAG
- **Lab:** RAG concept demonstration and exploration

### **Day 2: Data Challenges and LangChain Solutions**
- Different data formats: txt, md, pdf, html challenges
- How LangChain framework addresses data complexity
- Strategies for providing knowledge and data to AI
- The critical importance of correct, high-quality data
- **Lab:** Data preparation and formatting exercises

### **Day 3: Databases and Vector Storage**
- Introduction to database concepts
- Installing and running PostgreSQL
- PostgreSQL UI vs Server architecture
- Understanding relational databases
- Data vs Schema: structural concepts
- LLM embeddings and vector databases
- **Lab:** Set up PostgreSQL and explore database concepts

### **Day 4: Practical RAG Implementation**
- Building domain expert chatbots with LangChain and Streamlit
- Using different AI models within LangChain framework
- Integration strategies for knowledge bases
- **Lab:** Create a functional RAG system for specific domain

---

## **Week 6: AI Agents and Automation**

### **Day 1: No-Code/Low-Code Automation Platforms**
- Introduction to n8n automation platform
- Building RAG systems with no-code tools in n8n
- n8n integrations with different services and APIs
- Visual workflow creation and management
- **Lab:** Create automated workflows using n8n

### **Day 2: The Age of AI Agents**
- What defines an AI agent
- 2025: The year AI agents go mainstream
- Why businesses require AI agents for competitive advantage
- The emerging need for 'AI engineers'
- LLM vs AI agent: understanding the differences
- AI agents vs AI systems: architectural distinctions
- **Lab:** Design conceptual AI agent workflows

### **Day 3: OpenAI Agent SDK and Frameworks**
- Introduction to AI agent frameworks and their necessity
- Why standardized frameworks are essential
- Analyzing and building 'deep research' agents with OpenAI SDK
- Agent architecture and design patterns
- **Lab:** Experiment with OpenAI agent SDK tools

### **Day 4: Data Analysis Agent Practice**
- PostgreSQL database recap and integration
- Restoring and working with sample databases
- Building Streamlit agents for natural language database queries
- Creating intelligent data analysis workflows
- **Lab:** Build a complete data analyst agent system

---

## **Week 7: Model Training and Fine-Tuning**

### **Day 1: Understanding Model Training Theory**
- Why training from scratch is extremely complex
- Fine-tuning as a practical alternative
- When and why to fine-tune vs alternatives
- Fine-tuning vs RAG: choosing the right approach
- Understanding the challenges of fine-tuning
- Base models vs Instruction models
- Introduction to HuggingFace ecosystem
- **Lab:** Explore HuggingFace model repository

### **Day 2: Preparing for Fine-Tuning**
- Deep dive into Hugging Face platform analysis
- Understanding datasets and their importance
- Model classifications and selection criteria
- Ollama integration and its necessity
- Google Colab notebooks and GPU requirements
- **Lab:** Dataset analysis and preparation exercises

### **Day 3: Fine-Tuning with Unsloth Framework**
- Fine-tuning as a service through OpenAI
- Introduction to Unsloth framework and its advantages
- Understanding Unsloth documentation and resources
- Choosing the right base model for fine-tuning
- Fine-tuning Llama 3.2 with Unsloth
- Testing and evaluating fine-tuned models
- Launching fine-tuned models with Ollama
- **Lab:** Complete fine-tuning workflow using Unsloth

### **Day 4: Hands-On Fine-Tuning Practice**
- Dataset modification and optimization techniques
- Practical fine-tuning with Unsloth framework
- Model evaluation and performance testing
- Uploading new models to HuggingFace
- **Lab:** End-to-end fine-tuning project

---

## **Week 8: Multimodal AI and Advanced Applications**

### **Day 1: Vision and Image Generation**
- Understanding multimodal AI models and capabilities
- Computer vision fundamentals for non-programmers
- Image analysis with GPT-4 Vision
- Image generation with DALL-E, Midjourney, and alternatives
- Practical applications of vision AI in business
- Building image analysis applications without coding
- **Lab:** Create image analysis and generation workflows

### **Day 2: Voice and Audio AI Applications**
- Text-to-speech (TTS) technology overview
- Speech-to-text (STT) and transcription services
- Voice cloning and synthesis technologies
- OpenAI's voice models and capabilities
- ElevenLabs for professional voice generation
- Building voice-enabled applications
- Audio content generation for various use cases
- **Lab:** Create voice-powered applications and content

### **Day 3: Video Processing and Generation**
- AI-powered video analysis and understanding
- Video generation tools and platforms
- Sora, Veo3, and other cutting-edge video AI platforms
- Automated video editing and post-production
- Creating educational content with AI assistance
- Video transcription and summarization
- **Lab:** Video creation and editing using AI tools

### **Day 4: Advanced Multimodal Integration**
- Combining text, image, voice, and video capabilities
- Building comprehensive multimodal AI assistants
- Document processing with vision models
- Real-world multimodal use cases across industries
- Future trends in multimodal AI development
- Course recap and next steps for continued learning
- **Lab:** Create an integrated multimodal AI solution
